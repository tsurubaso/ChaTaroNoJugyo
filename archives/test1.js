import ollama from "ollama";
import readline from "readline";

// ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’èª­ã‚€æº–å‚™
const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout,
});

// AIã«è³ªå•ã™ã‚‹é–¢æ•°
async function askAgent(question) {
  const response = await ollama.chat({
    model: "mistral",
    messages: [
      { role: "system", content: "You are a helpful AI agent." },
      { role: "user", content: question },
    ],
  });

  console.log("\nðŸ¤– Agent:", response.message.content);
}

// ãƒ«ãƒ¼ãƒ—ï¼ˆä¼šè©±ã‚’ç¶šã‘ã‚‹ï¼‰
function start() {
  rl.question("\nðŸ§‘ You: ", async (input) => {
    if (input === "exit") {
      console.log("bye bye ðŸ‘‹");
      rl.close();
      return;
    }

    await askAgent(input);
    start();
  });
}

console.log("=== chaTaro Agent v0 ===");
console.log("Type 'exit' to stop.\n");

start();